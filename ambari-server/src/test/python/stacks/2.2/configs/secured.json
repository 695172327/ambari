{
    "roleCommand": "SERVICE_CHECK",
    "clusterName": "c1",
    "hostname": "c6401.ambari.apache.org",
    "hostLevelParams": {
        "jdk_location": "http://c6401.ambari.apache.org:8080/resources/",
        "ambari_db_rca_password": "mapred",
        "ambari_db_rca_url": "jdbc:postgresql://c6401.ambari.apache.org/ambarirca",
        "jce_name": "UnlimitedJCEPolicyJDK7.zip",
        "stack_version": "2.2",
        "stack_name": "HDP",
        "ambari_db_rca_driver": "org.postgresql.Driver",
        "jdk_name": "jdk-7u67-linux-x64.tar.gz",
        "ambari_db_rca_username": "mapred",
        "java_home": "/usr/jdk64/jdk1.7.0_45",
        "java_version": "8",
        "db_name": "ambari"
    },
    "commandType": "EXECUTION_COMMAND",
    "roleParams": {},
    "serviceName": "SLIDER",
    "role": "SLIDER",
    "commandParams": {
        "command_timeout": "300",
        "service_package_folder": "OOZIE",
        "script_type": "PYTHON",
        "script": "scripts/service_check.py",
        "excluded_hosts": "host1,host2"
    },
    "taskId": 152,
    "public_hostname": "c6401.ambari.apache.org",
    "configurations": {
        "spark-defaults": {
            "spark.yarn.applicationMaster.waitTries": "10", 
            "spark.history.kerberos.keytab": "/etc/security/keytabs/spark.service.keytab", 
            "spark.yarn.preserve.staging.files": "false", 
            "spark.yarn.submit.file.replication": "3", 
            "spark.history.kerberos.principal": "spark/_HOST@EXAMPLE.COM", 
            "spark.yarn.driver.memoryOverhead": "384", 
            "spark.yarn.queue": "default", 
            "spark.yarn.containerLauncherMaxThreads": "25", 
            "spark.yarn.scheduler.heartbeat.interval-ms": "5000", 
            "spark.history.ui.port": "18080", 
            "spark.yarn.max.executor.failures": "3", 
            "spark.driver.extraJavaOptions": "", 
            "spark.history.provider": "org.apache.spark.deploy.yarn.history.YarnHistoryProvider", 
            "spark.yarn.am.extraJavaOptions": "", 
            "spark.yarn.executor.memoryOverhead": "384"
        },
        "spark-javaopts-properties": {
            "content": " "
        }, 
        "spark-log4j-properties": {
            "content": "\n# Set everything to be logged to the console\nlog4j.rootCategory=INFO, console\nlog4j.appender.console=org.apache.log4j.ConsoleAppender\nlog4j.appender.console.target=System.err\nlog4j.appender.console.layout=org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n\n\n# Settings to quiet third party logs that are too verbose\nlog4j.logger.org.eclipse.jetty=WARN\nlog4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR\nlog4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO\nlog4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO"
        },
        "spark-env": {
            "content": "\n#!/usr/bin/env bash\n\n# This file is sourced when running various Spark programs.\n# Copy it as spark-env.sh and edit that to configure Spark for your site.\n\n# Options read in YARN client mode\n#SPARK_EXECUTOR_INSTANCES=\"2\" #Number of workers to start (Default: 2)\n#SPARK_EXECUTOR_CORES=\"1\" #Number of cores for the workers (Default: 1).\n#SPARK_EXECUTOR_MEMORY=\"1G\" #Memory per Worker (e.g. 1000M, 2G) (Default: 1G)\n#SPARK_DRIVER_MEMORY=\"512 Mb\" #Memory for Master (e.g. 1000M, 2G) (Default: 512 Mb)\n#SPARK_YARN_APP_NAME=\"spark\" #The name of your application (Default: Spark)\n#SPARK_YARN_QUEUE=\"~@~Xdefault~@~Y\" #The hadoop queue to use for allocation requests (Default: @~Xdefault~@~Y)\n#SPARK_YARN_DIST_FILES=\"\" #Comma separated list of files to be distributed with the job.\n#SPARK_YARN_DIST_ARCHIVES=\"\" #Comma separated list of archives to be distributed with the job.\n\n# Generic options for the daemons used in the standalone deploy mode\n\n# Alternate conf dir. (Default: ${SPARK_HOME}/conf)\nexport SPARK_CONF_DIR=${SPARK_HOME:-{{spark_home}}}/conf\n\n# Where log files are stored.(Default:${SPARK_HOME}/logs)\n#export SPARK_LOG_DIR=${SPARK_HOME:-{{spark_home}}}/logs\nexport SPARK_LOG_DIR={{spark_log_dir}}\n\n# Where the pid file is stored. (Default: /tmp)\nexport SPARK_PID_DIR={{spark_pid_dir}}\n\n# A string representing this instance of spark.(Default: $USER)\nSPARK_IDENT_STRING=$USER\n\n# The scheduling priority for daemons. (Default: 0)\nSPARK_NICENESS=0\n\nexport HADOOP_HOME=${HADOOP_HOME:-{{hadoop_home}}}\nexport HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-{{hadoop_conf_dir}}}\n\n# The java implementation to use.\nexport JAVA_HOME={{java_home}}\n\nif [ -d \"/etc/tez/conf/\" ]; then\n  export TEZ_CONF_DIR=/etc/tez/conf\nelse\n  export TEZ_CONF_DIR=\nfi", 
            "spark_pid_dir": "/var/run/spark", 
            "spark_log_dir": "/var/log/spark", 
            "spark_group": "spark", 
            "spark_user": "spark"
        },
		"spark-metrics-properties": {
            "content": "\n# syntax: [instance].sink|source.[name].[options]=[value]\n\n# This file configures Spark's internal metrics system. The metrics system is\n# divided into instances which correspond to internal components.\n# Each instance can be configured to report its metrics to one or more sinks.\n# Accepted values for [instance] are \"master\", \"worker\", \"executor\", \"driver\",\n# and \"applications\". A wild card \"*\" can be used as an instance name, in\n# which case all instances will inherit the supplied property.\n#\n# Within an instance, a \"source\" specifies a particular set of grouped metrics.\n# there are two kinds of sources:\n# 1. Spark internal sources, like MasterSource, WorkerSource, etc, which will\n# collect a Spark component's internal state. Each instance is paired with a\n# Spark source that is added automatically.\n# 2. Common sources, like JvmSource, which will collect low level state.\n# These can be added through configuration options and are then loaded\n# using reflection.\n#\n# A \"sink\" specifies where metrics are delivered to. Each instance can be\n# assigned one or more sinks.\n#\n# The sink|source field specifies whether the property relates to a sink or\n# source.\n#\n# The [name] field specifies the name of source or sink.\n#\n# The [options] field is the specific property of this source or sink. The\n# source or sink is responsible for parsing this property.\n#\n# Notes:\n# 1. To add a new sink, set the \"class\" option to a fully qualified class\n# name (see examples below).\n# 2. Some sinks involve a polling period. The minimum allowed polling period\n# is 1 second.\n# 3. Wild card properties can be overridden by more specific properties.\n# For example, master.sink.console.period takes precedence over\n# *.sink.console.period.\n# 4. A metrics specific configuration\n# \"spark.metrics.conf=${SPARK_HOME}/conf/metrics.properties\" should be\n# added to Java properties using -Dspark.metrics.conf=xxx if you want to\n# customize metrics system. You can also put the file in ${SPARK_HOME}/conf\n# and it will be loaded automatically.\n# 5. MetricsServlet is added by default as a sink in master, worker and client\n# driver, you can send http request \"/metrics/json\" to get a snapshot of all the\n# registered metrics in json format. For master, requests \"/metrics/master/json\" and\n# \"/metrics/applications/json\" can be sent seperately to get metrics snapshot of\n# instance master and applications. MetricsServlet may not be configured by self.\n#\n\n## List of available sinks and their properties.\n\n# org.apache.spark.metrics.sink.ConsoleSink\n# Name: Default: Description:\n# period 10 Poll period\n# unit seconds Units of poll period\n\n# org.apache.spark.metrics.sink.CSVSink\n# Name: Default: Description:\n# period 10 Poll period\n# unit seconds Units of poll period\n# directory /tmp Where to store CSV files\n\n# org.apache.spark.metrics.sink.GangliaSink\n# Name: Default: Description:\n# host NONE Hostname or multicast group of Ganglia server\n# port NONE Port of Ganglia server(s)\n# period 10 Poll period\n# unit seconds Units of poll period\n# ttl 1 TTL of messages sent by Ganglia\n# mode multicast Ganglia network mode ('unicast' or 'multicast')\n\n# org.apache.spark.metrics.sink.JmxSink\n\n# org.apache.spark.metrics.sink.MetricsServlet\n# Name: Default: Description:\n# path VARIES* Path prefix from the web server root\n# sample false Whether to show entire set of samples for histograms ('false' or 'true')\n#\n# * Default path is /metrics/json for all instances except the master. The master has two paths:\n# /metrics/aplications/json # App information\n# /metrics/master/json # Master information\n\n# org.apache.spark.metrics.sink.GraphiteSink\n# Name: Default: Description:\n# host NONE Hostname of Graphite server\n# port NONE Port of Graphite server\n# period 10 Poll period\n# unit seconds Units of poll period\n# prefix EMPTY STRING Prefix to prepend to metric name\n\n## Examples\n# Enable JmxSink for all instances by class name\n#*.sink.jmx.class=org.apache.spark.metrics.sink.JmxSink\n\n# Enable ConsoleSink for all instances by class name\n#*.sink.console.class=org.apache.spark.metrics.sink.ConsoleSink\n\n# Polling period for ConsoleSink\n#*.sink.console.period=10\n\n#*.sink.console.unit=seconds\n\n# Master instance overlap polling period\n#master.sink.console.period=15\n\n#master.sink.console.unit=seconds\n\n# Enable CsvSink for all instances\n#*.sink.csv.class=org.apache.spark.metrics.sink.CsvSink\n\n# Polling period for CsvSink\n#*.sink.csv.period=1\n\n#*.sink.csv.unit=minutes\n\n# Polling directory for CsvSink\n#*.sink.csv.directory=/tmp/\n\n# Worker instance overlap polling period\n#worker.sink.csv.period=10\n\n#worker.sink.csv.unit=minutes\n\n# Enable jvm source for instance master, worker, driver and executor\n#master.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#worker.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource\n\n#executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource"
        },
        "slider-client": {
            "slider.zookeeper.quorum": "c6401.ambari.apache.org:2181",
            "yarn.application.classpath": "/etc/hadoop/conf,/usr/lib/hadoop/*,/usr/lib/hadoop/lib/*,/usr/lib/hadoop-hdfs/*,/usr/lib/hadoop-hdfs/lib/*,/usr/lib/hadoop-yarn/*,/usr/lib/hadoop-yarn/lib/*,/usr/lib/hadoop-mapreduce/*,/usr/lib/hadoop-mapreduce/lib/*",
            "yarn.resourcemanager.address": "c6401.ambari.apache.org:8050",
            "yarn.resourcemanager.scheduler.address": "c6401.ambari.apache.org:8030",
            "slider.yarn.queue": "default",
            "fs.defaultFS": "hdfs://c6401.ambari.apache.org:8020"
        },
        "cluster-env": {
            "security_enabled": "true",
            "ignore_groupsusers_create": "false",
            "smokeuser": "ambari-qa",
            "kerberos_domain": "EXAMPLE.COM",
            "user_group": "hadoop",
            "smokeuser_keytab": "/etc/security/keytabs/smokeuser.headless.keytab",
            "smokeuser_principal_name": "ambari-qa@EXAMPLE.COM",
            "kinit_path_local": "/usr/bin"
        },
        "webhcat-site": {
            "templeton.jar": "/usr/hdp/current/hive-webhcat/share/webhcat/svr/lib/hive-webhcat-*.jar",
            "templeton.pig.archive": "hdfs:///hdp/apps/{{ hdp_stack_version }}/pig/pig.tar.gz",
            "templeton.hive.archive": "hdfs:///hdp/apps/{{ hdp_stack_version }}/hive/hive.tar.gz",
            "templeton.sqoop.archive": "hdfs:///hdp/apps/{{ hdp_stack_version }}/sqoop/sqoop.tar.gz",
            "templeton.streaming.jar": "hdfs:///hdp/apps/{{ hdp_stack_version }}/mapreduce/hadoop-streaming.jar"
        },
        "slider-log4j": {
            "content": "log4jproperties\nline2"
        },
        "slider-env": {
            "content": "envproperties\nline2"
        },
        "knox-env": {
            "knox_master_secret": "sa",
            "knox_group": "knox",
            "knox_pid_dir": "/var/run/knox",
            "knox_user": "knox"
        }
    },
    "configuration_attributes": {},
    "configurationTags": {
        "slider-client": {
            "tag": "version1"
        },
        "slider-log4j": {
            "tag": "version1"
        },
        "slider-env": {
            "tag": "version1"
        }
    },
    "commandId": "7-1",
    "clusterHostInfo": {
        "ambari_server_host": [
            "c6401.ambari.apache.org"
        ],
        "all_ping_ports": [
            "8670",
            "8670"
        ],
        "rm_host": [
            "c6402.ambari.apache.org"
        ],
        "all_hosts": [
            "c6401.ambari.apache.org",
            "c6402.ambari.apache.org"
        ]
    }
}
